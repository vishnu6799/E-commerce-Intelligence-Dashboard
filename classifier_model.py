# -*- coding: utf-8 -*-
"""Classifier Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11xjckMp5s5yPkKhMxwS0IGoWrTJqWJ9m
"""

import pandas as pd
import numpy as np

train_df = pd.read_csv("train_data.csv")
train_df.head(10)

train_df.info()

train_df.isnull().sum()

train_df.describe()

test_df = pd.read_csv("test_data.csv")
test_df.head(10)

test_df.info()

test_df.isnull().sum()

print("Shape of Training dataset:", train_df.shape)
print("Shape of Testing Dataset:",test_df.shape)

from sklearn.preprocessing import LabelEncoder, MinMaxScaler

le = LabelEncoder()
train_df["page2_clothing_model"] = le.fit_transform(train_df["page2_clothing_model"])
test_df["page2_clothing_model"] = le.fit_transform(test_df["page2_clothing_model"])

train_df.head()

scaler = MinMaxScaler()
numerical_cols = ['price']

train_df[numerical_cols] = scaler.fit_transform(train_df[numerical_cols])
test_df[numerical_cols] = scaler.transform(test_df[numerical_cols])

import matplotlib.pyplot as plt
import seaborn as sns

sns.countplot(x='page1_main_category', data=train_df)
plt.title('Main Product Category Distribution')
plt.xlabel('Category (1-Trousers, 2-Skirts, 3-Blouses, 4-Sale)')
plt.ylabel('Count')
plt.show()

sns.histplot(train_df['price'], bins=20, kde=True)
plt.title('Product Price Distribution')
plt.xlabel('Price (Scaled)')
plt.ylabel('Frequency')
plt.show()

sns.countplot(x='model_photography', data=train_df)
plt.title('Model Photography Type')
plt.xlabel('1 - En face, 2 - Profile')
plt.ylabel('Count')
plt.show()

session_clicks = train_df.groupby('session_id')['order'].count().reset_index(name='clicks')

sns.histplot(session_clicks['clicks'], bins=20)
plt.title('Session Length (Number of Clicks)')
plt.xlabel('Clicks per Session')
plt.ylabel('Number of Sessions')
plt.show()

page_views = train_df.groupby('session_id')['page'].nunique().reset_index(name='unique_pages')

sns.histplot(page_views['unique_pages'], bins=10)
plt.title('Unique Pages Viewed Per Session')
plt.xlabel('Unique Pages')
plt.ylabel('Number of Sessions')
plt.show()

plt.figure(figsize=(12, 6))
corr = train_df.select_dtypes(include=['int', 'float']).corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.show()

train_df['date'] = pd.to_datetime(train_df[['year', 'month', 'day']])
train_df['day_of_week'] = train_df['date'].dt.day_name()

sns.countplot(x='day_of_week', data=train_df, order=[
    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'
])
plt.title('Activity by Day of the Week')
plt.xticks(rotation=45)
plt.show()

sns.countplot(x='price_2', data=train_df)
plt.title('Price Above Category Average (price_2)')
plt.xlabel('1 - Yes, 2 - No')
plt.ylabel('Count')
plt.show()

sns.countplot(x='colour', data=train_df, order=train_df['colour'].value_counts().index)
plt.title('Clothing Colour Preferences')
plt.xlabel('Colour Code')
plt.ylabel('Count')
plt.show()

sample_df = train_df.sample(n=500, random_state=42)
sns.pairplot(sample_df[['price', 'page', 'order', 'page1_main_category']], diag_kind='kde')
plt.suptitle('Pairplot of Select Features', y=1.02)
plt.show()

sns.countplot(x='location', data=train_df)
plt.title('Click Position on Page')
plt.xlabel('Location (1-Top Left to 6-Bottom Right)')
plt.ylabel('Click Count')
plt.show()

session_length = train_df.groupby('session_id')['order'].count().rename('session_length')
session_length

unique_pages = train_df.groupby('session_id')['page'].nunique().rename('unique_pages')
unique_pages

first_category = train_df.sort_values(['session_id', 'order']).groupby('session_id')['page1_main_category'].first().rename('first_clicked_category')
first_category

last_category = train_df.sort_values(['session_id', 'order']).groupby('session_id')['page1_main_category'].last().rename('last_clicked_category')
last_category

bounce_flag = session_length.apply(lambda x: 1 if x == 1 else 0).rename('is_bounce')
bounce_flag

exit_page = train_df.sort_values(['session_id', 'order']).groupby('session_id')['page'].last().rename('exit_page')
exit_page

session_features = pd.concat([
    session_length,
    unique_pages,
    first_category,
    last_category,
    bounce_flag,
    exit_page,
], axis=1).reset_index()

# Step 1: Get list of converted session_ids (those that viewed a product from SALE category, i.e., category 4)
converted_sessions = train_df[train_df['page1_main_category'] == 4]['session_id'].unique()

# Step 2: Add target column to session_features
session_features['converted'] = session_features['session_id'].isin(converted_sessions).astype(int)

print(session_features['converted'].value_counts())
sns.countplot(x='converted', data=session_features)
plt.title("Class Distribution: Converted vs Not Converted")
plt.xlabel("Converted (1) or Not (0)")
plt.ylabel("Session Count")
plt.show()

from sklearn.model_selection import train_test_split

X = session_features.drop(['session_id', 'converted'], axis=1)
y = session_features['converted']

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.2)

#!pip install -U scikit-learn
!pip install --upgrade imbalanced-learn

from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

rus = RandomUnderSampler(random_state=42)
X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)

from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression(class_weight='balanced', random_state=42)
logreg.fit(X_train, y_train)

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(class_weight='balanced', random_state=42)
dt.fit(X_train, y_train)

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=100)
rf.fit(X_train, y_train)

from xgboost import XGBClassifier
xgb = XGBClassifier(scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]),
                    use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb.fit(X_train, y_train)

from sklearn.neural_network import MLPClassifier
mlp = MLPClassifier(random_state=42, max_iter=300)
mlp.fit(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
models = {'LogReg': logreg, 'DecisionTree': dt, 'RandomForest': rf, 'XGBoost': xgb, 'MLP': mlp}

for name, model in models.items():
    y_pred = model.predict(X_test)
    print(f"\n=== {name} ===")
    print(classification_report(y_test, y_pred))
    print("ROC-AUC:", roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, f1_score

model_scores = {}
plt.figure(figsize=(10, 7))

for name, model in models.items():
    y_proba = model.predict_proba(X_test)[:, 1]
    y_pred = model.predict(X_test)
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)
    f1 = f1_score(y_test, y_pred)

    model_scores[name] = {'roc_auc': roc_auc, 'f1_score': f1}
    plt.plot(fpr, tpr, label=f'{name} (AUC={roc_auc:.2f}, F1={f1:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.title('ROC Curve Comparison')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()

import joblib
joblib.dump(mlp, "best_classifier_model.pkl")

